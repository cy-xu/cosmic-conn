from itertools import count
import os
import collections
from os import name
import numpy as np

from astropy.io import fits, ascii
from astropy.table import Table, Column, MaskedColumn

# https://stackoverflow.com/questions/6323860/sibling-package-imports
if __name__ == "__main__" and __package__ is None:
    from sys import path
    from os.path import dirname as dir
    path.append(dir(path[0]))
    __package__ = "root_dir"

from src.banzai_stats import *

EXTENSIONS = ['fits', 'fz']

def is_fits_file(filename):
    filename = filename.lower()
    return any(filename.endswith(extension) for extension in EXTENSIONS)

def compute_MAD(target_dir):
    photon_counts = {}

    # first go through all frames to count photons
    for root, dirs, files in os.walk(f'data/pod_sync/SEP_MIN2/{target_dir}'):
        # avoid temp files generated by Mac's Finder
        files = [f for f in files if not f[0] == '.']

        if 'masked_fits' not in root:
            continue

        for f in files:
            if is_fits_file(f):
                path = os.path.join(root, f)
                print(f)
            else:
                continue

            with fits.open(path) as hdu:
                hdr = hdu['SCI'].header
                frmtotal = hdr['FRMTOTAL']
                exptime = hdr['EXPTIME']
                readnoise = hdr['RDNOISE']

                src_count = len(hdu['CAT'].data)

                if frmtotal >= 3 and frmtotal <= 5:
                    # skip hdul[0] primary frame
                    for i in range(1):
                        frm = hdu[2 + i].data
                        key = os.path.join(root, f)
                        frame_mad = median_absolute_deviation(frm)
                        med = np.median(frm)
                        photon_counts[src_count] = [frame_mad, med, exptime, readnoise]


    # value_sroted = {k: v for k, v in sorted(photon_counts.items(), key=lambda item: item[1])}
    key_sorted = collections.OrderedDict(sorted(photon_counts.items()))

    with open(logger_fname, "a") as log_file:
        log_file.write(f'{target_dir}\n\n')

        log_file.write(f'{"Source": <10} {"MAD": <10} {"Median": <10} {"Exp Time": <10} {"Read Noise"} \n')

        counter = 0
        for k, v in key_sorted.items():
            mad = str(round(v[0], 3))
            med = str(round(v[1], 3))
            exptime = str(round(v[2]))
            txt = f'{k: <10} {mad: <10} {med: <10} {exptime: <10} {v[3]}\n'
            print(txt)
            log_file.write(txt)

            counter += 1
            if counter > top_n:
                break

        log_file.write(f'\n')


if __name__ == '__main__':
    top_n = 30

    # logging
    logger_fname = os.path.join('scripts', 'frames_MAD.txt')

    try:
        os.remove(logger_fname)
    except:
        pass

    # table = Table(None, names=['Source Count', 'MAD', 'Meidan', 'Exposure Time'])

    dirs_to_check = \
        ['coj0m4a_2019_EXPOSE_done',
        'coj0m4b_2019_EXPOSE_done',
        'coj1m0_2019_EXPOSE_50s_done',
        'coj2m0_2019_EXPOSE_50s_done',
        'elp1m0a_2019_EXPOSE_50s_done',
        'lsc0m4_2019_EXPOSE_done',
        'ogg0m4b_2019_EXPOSE_done',
        'ogg0m4c_2019_EXPOSE_done',
        'ogg2m0_2019_EXPOSE_50s_done',
        'tfn0m4a_2019_EXPOSE_done',]

    for d in dirs_to_check:
        compute_MAD(d)

    # table.write([k, mad, v[1], v[2]], format='csv')
